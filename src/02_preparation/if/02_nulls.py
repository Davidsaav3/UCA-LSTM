import pandas as pd  # PARA MANEJO DE DATAFRAMES
from sklearn.impute import SimpleImputer  # PARA CORREGIR VALORES NULOS
import json  # PARA GUARDAR INFORMACI√ìN DE COLUMNAS EN FORMATO JSON

# PAR√ÅMETROS 
INPUT_FILE = '../../../results/01_dataset/infrastructure_data_realtime.csv'                  # RUTA DEL DATASET ORIGINAL
OUTPUT_CSV = '../../../results/02_preparation/02_nulls.csv'  # RUTA DEL DATASET FINAL SIN NULOS
OUTPUT_JSON = '../../../results/02_preparation/02_aux.json'  # RUTA DEL JSON CON INFORMACI√ìN DE COLUMNAS

NUMERIC_STRATEGY = 'median'                            
# ESTRATEGIA PARA RELLENAR NaN EN COLUMNAS NUM√âRICAS
# OPCIONES:
# - 'mean'       : REEMPLAZA CON LA MEDIA. IMPLICA QUE LOS DATOS SE AJUSTAN AL PROMEDIO, PERO PUEDE SER SENSIBLE A OUTLIERS.
# - 'median'     : REEMPLAZA CON LA MEDIANA. RESISTENTE A OUTLIERS Y MANTIENE LA DISTRIBUCI√ìN CENTRAL.
# - 'constant'   : REEMPLAZA CON FILL_CONSTANT_NUMERIC. PUEDE INTRODUCIR SESGO SI EL VALOR NO REPRESENTA LA DISTRIBUCI√ìN REAL.
# IMPLICA QUE NO QUEDAR√ÅN NaN Y LOS MODELOS PODR√ÅN PROCESAR TODAS LAS FILAS

FILL_CONSTANT_NUMERIC = 0                               
# VALOR FIJO PARA COLUMNAS NUM√âRICAS SI strategy='constant'
# IMPLICA QUE TODOS LOS NaN SE CONVERTIR√ÅN EN 0, LO QUE PUEDE INTRODUCIR SESGO SI 0 NO ES REPRESENTATIVO

CATEGORICAL_STRATEGY = 'most_frequent'                 
# ESTRATEGIA PARA RELLENAR NaN EN COLUMNAS CATEG√ìRICAS
# OPCIONES:
# - 'most_frequent' : REEMPLAZA CON LA CATEGOR√çA M√ÅS FRECUENTE. PUEDE SESGAR HACIA ESA CATEGOR√çA SI HAY MUCHOS NaN.
# - 'constant'      : REEMPLAZA CON FILL_CONSTANT_CATEGORICAL. TRATA LOS NaN COMO NUEVA CATEGOR√çA SEPARADA.
# IMPLICA QUE NO HABR√Å NaN Y LAS COLUMNAS PODR√ÅN SER CODIFICADAS PARA MODELOS

FILL_CONSTANT_CATEGORICAL = 'unknown'                  
# VALOR FIJO PARA COLUMNAS CATEG√ìRICAS SI strategy='constant'
# IMPLICA QUE TODOS LOS NaN SE CONVERTIR√ÅN EN 'UNKNOWN' Y SE TRATAR√ÅN COMO NUEVA CATEGOR√çA EN LOS MODELOS

REMOVE_EMPTY_COLUMNS = True                             # ELIMINAR COLUMNAS COMPLETAMENTE VAC√çAS
SHOW_INFO = True                                       # MOSTRAR MENSAJES INFORMATIVOS EN PANTALLA
SAVE_INTERMEDIATE = True                              # GUARDAR CSV INTERMEDIO ANTES DE CORREGIR NULOS

# CARGAR DATASET
df = pd.read_csv(INPUT_FILE, low_memory=False)  # LEER EL CSV DE ENTRADA
if SHOW_INFO:
    print(f"[ INFO ] Dataset cargado: {df.shape[0]} FILAS, {df.shape[1]} COLUMNAS")

# IDENTIFICAR COLUMNAS POR TIPO
num_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()  # DETECTAR COLUMNAS NUM√âRICAS
cat_cols = df.select_dtypes(include=['object','category']).columns.tolist()  # DETECTAR COLUMNAS CATEG√ìRICAS
if SHOW_INFO:
    print(f"[ INFO ] Columnas num√©ricas: {len(num_cols)}, Columnas categ√≥ricas: {len(cat_cols)}")

# GUARDAR INFORMACI√ìN INICIAL DE COLUMNAS
columns_info = {
    'categorical': cat_cols,                # LISTA DE COLUMNAS CATEG√ìRICAS DETECTADAS
    'numeric_imputed': num_cols,            # COLUMNAS NUM√âRICAS QUE SE CORREGIRAN
    'categorical_imputed': cat_cols,        # COLUMNAS CATEG√ìRICAS QUE SE CORREGIRAN
    'removed_empty_columns': []             # COLUMNAS VAC√çAS QUE SE ELIMINAR√ÅN
}

# ELIMINAR COLUMNAS COMPLETAMENTE VAC√çAS (OPCIONAL)
if REMOVE_EMPTY_COLUMNS:
    empty_cols = df.columns[df.isna().all()].tolist()  # DETECTAR COLUMNAS VAC√çAS
    df.drop(columns=empty_cols, inplace=True)          # ELIMINAR COLUMNAS VAC√çAS
    columns_info['removed_empty_columns'] = empty_cols  # GUARDAR LISTA DE COLUMNAS ELIMINADAS
    if SHOW_INFO:
        print(f"[ INFO ] Columnas completamente vac√≠as eliminadas: {len(empty_cols)}")

    # üîß ACTUALIZAR LISTAS DE COLUMNAS TRAS ELIMINAR VAC√çAS PARA EVITAR KeyError
    num_cols = [col for col in num_cols if col in df.columns]
    cat_cols = [col for col in cat_cols if col in df.columns]

# GUARDAR DATASET INTERMEDIO (OPCIONAL)
if SAVE_INTERMEDIATE:
    intermediate_csv = OUTPUT_CSV.replace('.csv','_intermediate.csv')  # NOMBRE DEL CSV INTERMEDIO
    df.to_csv(intermediate_csv, index=False)  # GUARDAR DATASET INTERMEDIO
    if SHOW_INFO:
        print(f"[ GUARDADO ] Dataset intermedio en '{intermediate_csv}'")

# CORREGIR COLUMNAS NUM√âRICAS
num_strategy_params = {'strategy': NUMERIC_STRATEGY}  # CONFIGURAR ESTRATEGIA
if NUMERIC_STRATEGY == 'constant':  # SI USAMOS CONSTANTE, DEFINIR VALOR
    num_strategy_params['fill_value'] = FILL_CONSTANT_NUMERIC

imputer_num = SimpleImputer(**num_strategy_params)  # CREAR OBJETO IMPUTER
df[num_cols] = imputer_num.fit_transform(df[num_cols])  # CORREGIR NULOS NUM√âRICOS
if SHOW_INFO:
    print(f"[ INFO ] Valores nulos num√©ricos imputados con '{NUMERIC_STRATEGY}'")

# CORREGIR COLUMNAS CATEG√ìRICAS
cat_strategy_params = {'strategy': CATEGORICAL_STRATEGY}  # CONFIGURAR ESTRATEGIA
if CATEGORICAL_STRATEGY == 'constant':  # SI USAMOS CONSTANTE, DEFINIR VALOR
    cat_strategy_params['fill_value'] = FILL_CONSTANT_CATEGORICAL

imputer_cat = SimpleImputer(**cat_strategy_params)  # CREAR OBJETO IMPUTER
df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])  # CORREGIR NULOS CATEG√ìRICOS
if SHOW_INFO:
    print(f"[ INFO ] Valores nulos categ√≥ricos imputados con '{CATEGORICAL_STRATEGY}'")

# GUARDAR DATASET FINAL
df.to_csv(OUTPUT_CSV, index=False)  # GUARDAR CSV FINAL SIN NULOS
if SHOW_INFO:
    print(f"[ GUARDADO ] Dataset final sin nulos en '{OUTPUT_CSV}'")
    print(f"[ INFO ] Dataset final: {df.shape[0]} FILAS, {df.shape[1]} COLUMNAS")

# GUARDAR INFORMACI√ìN DE COLUMNAS EN JSON
with open(OUTPUT_JSON, 'w') as f:
    json.dump(columns_info, f, indent=4)  # GUARDAR COLUMNAS CORREGIDAS Y ELIMINADAS
if SHOW_INFO:
    print(f"[ GUARDADO ] Columnas CORREGIDAS guardadas en '{OUTPUT_JSON}'")
